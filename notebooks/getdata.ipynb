{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob2 import glob\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "all_file_path=glob('../artifacts/sampledb/*.edf')\n",
    "print(len(all_file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../artifacts/sampledb\\\\hlp41.edf'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_file_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_file_path=[i for i in all_file_path if  'h' in i.split('\\\\')[1]]\n",
    "patient_file_path=[i for i in all_file_path if  's' in i.split('\\\\')[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    datax=mne.io.read_raw_edf(file_path,preload=True)\n",
    "    datax.set_eeg_reference()\n",
    "    datax.filter(l_freq=1,h_freq=45)\n",
    "    epochs=mne.make_fixed_length_epochs(datax,duration=25,overlap=0)\n",
    "    epochs=epochs.get_data()\n",
    "    return epochs #trials,channel,length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\FinalYearProject\\SA_Detection_CNN\\artifacts\\sampledb\\hlp41.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5852499  =      0.000 ... 23409.996 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "Not setting metadata\n",
      "936 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 936 events and 6250 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "data=read_data(healthy_file_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(936, 7, 6250)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from D:\\FinalYearProject\\SA_Detection_CNN\\artifacts\\sampledb\\hlp41.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5852499  =      0.000 ... 23409.996 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "Not setting metadata\n",
      "936 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 936 events and 6250 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\FinalYearProject\\SA_Detection_CNN\\artifacts\\sampledb\\hlp45.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5702499  =      0.000 ... 22809.996 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "Not setting metadata\n",
      "912 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 912 events and 6250 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\FinalYearProject\\SA_Detection_CNN\\artifacts\\sampledb\\slp37.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5252499  =      0.000 ... 21009.996 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "Not setting metadata\n",
      "840 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 840 events and 6250 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\FinalYearProject\\SA_Detection_CNN\\artifacts\\sampledb\\slp48.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5702499  =      0.000 ... 22809.996 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "Not setting metadata\n",
      "912 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 912 events and 6250 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\FinalYearProject\\SA_Detection_CNN\\artifacts\\sampledb\\slp59.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 3602499  =      0.000 ... 14409.996 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "Not setting metadata\n",
      "576 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 576 events and 6250 original time points ...\n",
      "0 bad epochs dropped\n",
      "Extracting EDF parameters from D:\\FinalYearProject\\SA_Detection_CNN\\artifacts\\sampledb\\slp60.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 5327499  =      0.000 ... 21309.996 secs...\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 45 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 45.00 Hz\n",
      "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
      "- Filter length: 825 samples (3.300 s)\n",
      "\n",
      "Not setting metadata\n",
      "852 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Using data from preloaded Raw for 852 events and 6250 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "control_epochs_array=[read_data(subject) for subject in healthy_file_path]\n",
    "patients_epochs_array=[read_data(subject) for subject in patient_file_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 4\n"
     ]
    }
   ],
   "source": [
    "control_epochs_labels=[len(i)*[0] for i in control_epochs_array]\n",
    "patients_epochs_labels=[len(i)*[1] for i in patients_epochs_array]\n",
    "print(len(control_epochs_labels),len(patients_epochs_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 6\n"
     ]
    }
   ],
   "source": [
    "data_list=control_epochs_array+patients_epochs_array\n",
    "label_list=control_epochs_labels+patients_epochs_labels\n",
    "print(len(data_list),len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_list=[[i]*len(j) for i, j in enumerate(data_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5028, 6250, 7) (5028,) (5028,)\n"
     ]
    }
   ],
   "source": [
    "data_array=np.vstack(data_list)\n",
    "label_array=np.hstack(label_list)\n",
    "group_array=np.hstack(groups_list)\n",
    "data_array=np.moveaxis(data_array,1,2)\n",
    "\n",
    "print(data_array.shape,label_array.shape,group_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/1c/c3/17c6aa1dd5bc8cea5bf00d0c3a021a5dd1680c250861cc877a7e556e4b9b/tensorflow-2.14.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.14.0-cp310-cp310-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.14.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.14.0 from https://files.pythonhosted.org/packages/cb/90/599c79a248dcae6935331113649de5d75427e320efde21b583648b498584/tensorflow_intel-2.14.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached tensorflow_intel-2.14.0-cp310-cp310-win_amd64.whl.metadata (4.8 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Using cached absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for h5py>=2.9.0 from https://files.pythonhosted.org/packages/25/5e/2e29933bd1dd67c76b56dd37f5950e6a0cf86ce67e9a9eb6761dac80c031/h5py-3.10.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached h5py-3.10.0-cp310-cp310-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/02/8c/dc970bc00867fe290e8c8a7befa1635af716a9ebdfe3fb9dce0ca4b522ce/libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata\n",
      "  Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes==0.2.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes==0.2.0 from https://files.pythonhosted.org/packages/55/51/c430b4f5f4a6df00aa41c1ee195e179489565e61cfad559506ca7442ce67/ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.23.5 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.26.0)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (23.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/c2/59/f89c04923d68595d359f4cd7adbbdf5e5d791257945f8873d88b2fd1f979/protobuf-4.24.4-cp310-abi3-win_amd64.whl.metadata\n",
      "  Using cached protobuf-4.24.4-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: setuptools in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (68.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from tensorflow-intel==2.14.0->tensorflow) (4.8.0)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached wrapt-1.14.1-cp310-cp310-win_amd64.whl (35 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.31.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/c7/40/d43d62a1da2d49700c3defddc307ca4b4e1a405a6ffd5fdacfcb4eea03da/grpcio-1.59.0-cp310-cp310-win_amd64.whl.metadata\n",
      "  Using cached grpcio-1.59.0-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tensorboard<2.15,>=2.14 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.15,>=2.14 from https://files.pythonhosted.org/packages/73/a2/66ed644f6ed1562e0285fcd959af17670ea313c8f331c46f79ee77187eb9/tensorboard-2.14.1-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard-2.14.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.15,>=2.14.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.15,>=2.14.0 from https://files.pythonhosted.org/packages/d1/da/4f264c196325bb6e37a6285caec5b12a03def489b57cc1fdac02bb6272cd/tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached tensorflow_estimator-2.14.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.15,>=2.14.0 (from tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for keras<2.15,>=2.14.0 from https://files.pythonhosted.org/packages/fe/58/34d4d8f1aa11120c2d36d7ad27d0526164b1a8ae45990a2fede31d0e59bf/keras-2.14.0-py3-none-any.whl.metadata\n",
      "  Using cached keras-2.14.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.14.0->tensorflow) (0.41.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/39/7c/2e4fa55a99f83ef9ef229ac5d59c44ceb90e2d0145711590c0fa39669f32/google_auth-2.23.3-py2.py3-none-any.whl.metadata\n",
      "  Using cached google_auth-2.23.3-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/bb/c1/50caaec6cadc1c6adc8fe351e03bd646d6e4dd17f55fca0f4c8d7ea8d3e9/Markdown-3.5-py3-none-any.whl.metadata\n",
      "  Using cached Markdown-3.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/da/61/6e9ff8258422d287eec718872fb71e05324356722ab658c8afda25f51539/tensorboard_data_server-0.7.1-py3-none-any.whl.metadata\n",
      "  Using cached tensorboard_data_server-0.7.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/b6/a5/54b01f663d60d5334f6c9c87c26274e94617a4fd463d812463626423b10d/werkzeug-3.0.0-py3-none-any.whl.metadata\n",
      "  Using cached werkzeug-3.0.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow) (2.1.3)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-intel==2.14.0->tensorflow)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached tensorflow-2.14.0-cp310-cp310-win_amd64.whl (2.1 kB)\n",
      "Using cached tensorflow_intel-2.14.0-cp310-cp310-win_amd64.whl (284.1 MB)\n",
      "Using cached ml_dtypes-0.2.0-cp310-cp310-win_amd64.whl (938 kB)\n",
      "Using cached absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Using cached grpcio-1.59.0-cp310-cp310-win_amd64.whl (3.7 MB)\n",
      "Using cached h5py-3.10.0-cp310-cp310-win_amd64.whl (2.7 MB)\n",
      "Using cached keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "Downloading protobuf-4.24.4-cp310-abi3-win_amd64.whl (430 kB)\n",
      "   ---------------------------------------- 0.0/430.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/430.5 kB ? eta -:--:--\n",
      "   ------- ------------------------------- 81.9/430.5 kB 919.0 kB/s eta 0:00:01\n",
      "   ---------- --------------------------- 122.9/430.5 kB 901.1 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 245.8/430.5 kB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 276.5/430.5 kB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 409.6/430.5 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  430.1/430.5 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 430.5/430.5 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.2/5.5 MB 12.2 MB/s eta 0:00:01\n",
      "   - -------------------------------------- 0.2/5.5 MB 7.6 MB/s eta 0:00:01\n",
      "   -- ------------------------------------- 0.3/5.5 MB 2.9 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.5/5.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.6/5.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.7/5.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.8/5.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 0.8/5.5 MB 2.8 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.0/5.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.1/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.1/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 1.2/5.5 MB 2.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 1.4/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.4/5.5 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.5/5.5 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.8/5.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.8/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 1.9/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 2.1/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 2.3/5.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 2.4/5.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.5/5.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 2.5/5.5 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 2.7/5.5 MB 2.5 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.8/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 2.9/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 3.0/5.5 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 3.3/5.5 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 3.5/5.5 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 3.7/5.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 2.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.1/5.5 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.3/5.5 MB 2.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 4.5/5.5 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 4.7/5.5 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 4.9/5.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 5.1/5.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 5.2/5.5 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "   ---------------------------------------- 0.0/440.7 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 143.4/440.7 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 378.9/440.7 kB 4.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 440.7/440.7 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\n",
      "   ---------------------------------------- 0.0/182.3 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 143.4/182.3 kB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 182.3/182.3 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.5-py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 101.7/101.7 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.0-py3-none-any.whl (226 kB)\n",
      "   ---------------------------------------- 0.0/226.6 kB ? eta -:--:--\n",
      "   ---------------------------------------  225.3/226.6 kB 6.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 226.6/226.6 kB 4.6 MB/s eta 0:00:00\n",
      "Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, opt-einsum, oauthlib, ml-dtypes, markdown, keras, h5py, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.3 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 h5py-3.10.0 keras-2.14.0 libclang-16.0.6 markdown-3.5 ml-dtypes-0.2.0 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.24.4 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-intel-2.14.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 werkzeug-3.0.0 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 6248, 5)           110       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 6248, 5)           20        \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 6248, 5)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 3124, 5)           0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 3122, 5)           80        \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 3122, 5)           0         \n",
      "                                                                 \n",
      " max_pooling1d_1 (MaxPoolin  (None, 1561, 5)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1561, 5)           0         \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 1559, 5)           80        \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 1559, 5)           0         \n",
      "                                                                 \n",
      " average_pooling1d (Average  (None, 779, 5)            0         \n",
      " Pooling1D)                                                      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 779, 5)            0         \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 777, 5)            80        \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 777, 5)            0         \n",
      "                                                                 \n",
      " average_pooling1d_1 (Avera  (None, 388, 5)            0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_4 (Conv1D)           (None, 386, 5)            80        \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 386, 5)            0         \n",
      "                                                                 \n",
      " global_average_pooling1d (  (None, 5)                 0         \n",
      " GlobalAveragePooling1D)                                         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 456 (1.78 KB)\n",
      "Trainable params: 446 (1.74 KB)\n",
      "Non-trainable params: 10 (40.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Conv1D,BatchNormalization,LeakyReLU,MaxPool1D,\\\n",
    "GlobalAveragePooling1D,Dense,Dropout,AveragePooling1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "def cnnmodel():\n",
    "    clear_session()\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D(filters=5,kernel_size=3,strides=1,input_shape=(6250,7)))#1\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPool1D(pool_size=2,strides=2))#2\n",
    "    model.add(Conv1D(filters=5,kernel_size=3,strides=1))#3\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(MaxPool1D(pool_size=2,strides=2))#4\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(filters=5,kernel_size=3,strides=1))#5\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(AveragePooling1D(pool_size=2,strides=2))#6\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv1D(filters=5,kernel_size=3,strides=1))#7\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(AveragePooling1D(pool_size=2,strides=2))#8\n",
    "    model.add(Conv1D(filters=5,kernel_size=3,strides=1))#9\n",
    "    model.add(LeakyReLU())\n",
    "    model.add(GlobalAveragePooling1D())#10\n",
    "    model.add(Dense(1,activation='sigmoid'))#11\n",
    "    \n",
    "    model.compile('adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model=cnnmodel()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Obtaining dependency information for scikit-learn from https://files.pythonhosted.org/packages/59/ed/548f6f686845d386a727a51a3daa411d95fc599649a2d54705f6773ac259/scikit_learn-1.3.1-cp310-cp310-win_amd64.whl.metadata\n",
      "  Downloading scikit_learn-1.3.1-cp310-cp310-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from scikit-learn) (1.26.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in d:\\finalyearproject\\sa_detection_cnn\\env\\lib\\site-packages (from scikit-learn) (1.11.3)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Obtaining dependency information for joblib>=1.1.1 from https://files.pythonhosted.org/packages/10/40/d551139c85db202f1f384ba8bcf96aca2f329440a844f924c8a0040b6d02/joblib-1.3.2-py3-none-any.whl.metadata\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Obtaining dependency information for threadpoolctl>=2.0.0 from https://files.pythonhosted.org/packages/81/12/fd4dea011af9d69e1cad05c75f3f7202cdcbeac9b712eea58ca779a72865/threadpoolctl-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl.metadata (10.0 kB)\n",
      "Downloading scikit_learn-1.3.1-cp310-cp310-win_amd64.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/9.3 MB 1.3 MB/s eta 0:00:08\n",
      "   ---------------------------------------- 0.1/9.3 MB 812.7 kB/s eta 0:00:12\n",
      "   ---------------------------------------- 0.1/9.3 MB 919.0 kB/s eta 0:00:10\n",
      "    --------------------------------------- 0.2/9.3 MB 1.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.2/9.3 MB 1.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.3/9.3 MB 1.2 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.4/9.3 MB 1.4 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.6/9.3 MB 1.7 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 0.7/9.3 MB 1.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 0.7/9.3 MB 1.7 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 0.8/9.3 MB 1.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.0/9.3 MB 1.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 1.1/9.3 MB 2.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.2/9.3 MB 2.0 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.3/9.3 MB 2.1 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 1.3/9.3 MB 2.1 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 1.6/9.3 MB 2.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.6/9.3 MB 2.1 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.7/9.3 MB 2.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 1.8/9.3 MB 2.0 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 1.9/9.3 MB 2.1 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 2.1/9.3 MB 2.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 2.3/9.3 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.4/9.3 MB 2.2 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.5/9.3 MB 2.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.7/9.3 MB 2.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 2.9/9.3 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.1/9.3 MB 2.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 3.2/9.3 MB 2.4 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 3.3/9.3 MB 2.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 3.6/9.3 MB 2.5 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.7/9.3 MB 2.6 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 3.9/9.3 MB 2.6 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 4.1/9.3 MB 2.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 4.2/9.3 MB 2.7 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 4.5/9.3 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.6/9.3 MB 2.7 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.8/9.3 MB 2.8 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 5.0/9.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.1/9.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.2/9.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 5.2/9.3 MB 2.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 5.5/9.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.7/9.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 5.8/9.3 MB 2.8 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 6.0/9.3 MB 2.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 6.2/9.3 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.3/9.3 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.4/9.3 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.4/9.3 MB 2.9 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 6.4/9.3 MB 2.9 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 6.6/9.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 6.9/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.0/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.1/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.2/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.4/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.5/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.5/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.5/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 7.6/9.3 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.9/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.2/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 8.3/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.5/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 8.6/9.3 MB 2.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 8.9/9.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.1/9.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.2/9.3 MB 2.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 2.9 MB/s eta 0:00:00\n",
      "Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "   ---------------------------------------- 0.0/302.2 kB ? eta -:--:--\n",
      "   ------------------ --------------------- 143.4/302.2 kB 8.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 302.2/302.2 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.2 scikit-learn-1.3.1 threadpoolctl-3.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold,LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "gkf=GroupKFold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "410/410 [==============================] - 18s 29ms/step - loss: 0.4294 - accuracy: 0.7754 - val_loss: 0.8961 - val_accuracy: 0.0064\n",
      "Epoch 2/50\n",
      "410/410 [==============================] - 11s 27ms/step - loss: 0.3892 - accuracy: 0.7791 - val_loss: 0.7392 - val_accuracy: 0.3590\n",
      "Epoch 3/50\n",
      "410/410 [==============================] - 11s 27ms/step - loss: 0.3591 - accuracy: 0.8045 - val_loss: 0.3982 - val_accuracy: 0.9541\n",
      "Epoch 4/50\n",
      "410/410 [==============================] - 11s 27ms/step - loss: 0.3074 - accuracy: 0.8539 - val_loss: 0.4282 - val_accuracy: 0.8889\n",
      "Epoch 5/50\n",
      "410/410 [==============================] - 11s 27ms/step - loss: 0.2700 - accuracy: 0.8839 - val_loss: 1.1733 - val_accuracy: 0.5256\n",
      "Epoch 6/50\n",
      "410/410 [==============================] - 11s 28ms/step - loss: 0.2416 - accuracy: 0.9032 - val_loss: 1.9033 - val_accuracy: 0.3654\n",
      "Epoch 7/50\n",
      "410/410 [==============================] - 12s 29ms/step - loss: 0.2189 - accuracy: 0.9066 - val_loss: 0.9022 - val_accuracy: 0.7254\n",
      "Epoch 8/50\n",
      "410/410 [==============================] - 12s 29ms/step - loss: 0.2073 - accuracy: 0.9176 - val_loss: 0.7261 - val_accuracy: 0.8056\n",
      "Epoch 9/50\n",
      "410/410 [==============================] - 12s 29ms/step - loss: 0.2099 - accuracy: 0.9123 - val_loss: 1.8241 - val_accuracy: 0.5032\n",
      "Epoch 10/50\n",
      "410/410 [==============================] - 12s 30ms/step - loss: 0.1792 - accuracy: 0.9316 - val_loss: 1.9629 - val_accuracy: 0.5118\n",
      "Epoch 11/50\n",
      "410/410 [==============================] - 12s 30ms/step - loss: 0.1776 - accuracy: 0.9294 - val_loss: 0.3881 - val_accuracy: 0.9284\n",
      "Epoch 12/50\n",
      "410/410 [==============================] - 12s 30ms/step - loss: 0.1728 - accuracy: 0.9340 - val_loss: 0.7931 - val_accuracy: 0.8387\n",
      "Epoch 13/50\n",
      "410/410 [==============================] - 13s 31ms/step - loss: 0.1699 - accuracy: 0.9387 - val_loss: 1.1021 - val_accuracy: 0.7853\n",
      "Epoch 14/50\n",
      "410/410 [==============================] - 13s 31ms/step - loss: 0.1668 - accuracy: 0.9379 - val_loss: 1.1891 - val_accuracy: 0.7799\n",
      "Epoch 15/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1611 - accuracy: 0.9367 - val_loss: 1.2375 - val_accuracy: 0.7724\n",
      "Epoch 16/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1571 - accuracy: 0.9416 - val_loss: 0.7655 - val_accuracy: 0.8761\n",
      "Epoch 17/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1584 - accuracy: 0.9401 - val_loss: 6.0736 - val_accuracy: 0.2457\n",
      "Epoch 18/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1547 - accuracy: 0.9438 - val_loss: 1.9645 - val_accuracy: 0.6688\n",
      "Epoch 19/50\n",
      "410/410 [==============================] - 13s 33ms/step - loss: 0.1471 - accuracy: 0.9445 - val_loss: 0.2243 - val_accuracy: 0.9701\n",
      "Epoch 20/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1441 - accuracy: 0.9457 - val_loss: 2.4839 - val_accuracy: 0.6378\n",
      "Epoch 21/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1385 - accuracy: 0.9487 - val_loss: 3.7976 - val_accuracy: 0.4904\n",
      "Epoch 22/50\n",
      "410/410 [==============================] - 13s 33ms/step - loss: 0.1506 - accuracy: 0.9457 - val_loss: 1.7181 - val_accuracy: 0.7489\n",
      "Epoch 23/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1358 - accuracy: 0.9482 - val_loss: 6.0352 - val_accuracy: 0.3312\n",
      "Epoch 24/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1403 - accuracy: 0.9484 - val_loss: 2.4670 - val_accuracy: 0.6763\n",
      "Epoch 25/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1445 - accuracy: 0.9455 - val_loss: 2.1524 - val_accuracy: 0.7286\n",
      "Epoch 26/50\n",
      "410/410 [==============================] - 13s 33ms/step - loss: 0.1360 - accuracy: 0.9448 - val_loss: 8.4560 - val_accuracy: 0.2265\n",
      "Epoch 27/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1453 - accuracy: 0.9477 - val_loss: 0.2636 - val_accuracy: 0.9615\n",
      "Epoch 28/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.2504 - accuracy: 0.9079 - val_loss: 1.1554 - val_accuracy: 0.8024\n",
      "Epoch 29/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1451 - accuracy: 0.9411 - val_loss: 1.1678 - val_accuracy: 0.8269\n",
      "Epoch 30/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1304 - accuracy: 0.9506 - val_loss: 1.6598 - val_accuracy: 0.7682\n",
      "Epoch 31/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1238 - accuracy: 0.9558 - val_loss: 7.9737 - val_accuracy: 0.2415\n",
      "Epoch 32/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1461 - accuracy: 0.9440 - val_loss: 0.9336 - val_accuracy: 0.8739\n",
      "Epoch 33/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1314 - accuracy: 0.9526 - val_loss: 2.8385 - val_accuracy: 0.6314\n",
      "Epoch 34/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1443 - accuracy: 0.9494 - val_loss: 1.8236 - val_accuracy: 0.7564\n",
      "Epoch 35/50\n",
      "410/410 [==============================] - 13s 33ms/step - loss: 0.1322 - accuracy: 0.9543 - val_loss: 1.1757 - val_accuracy: 0.8472\n",
      "Epoch 36/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1216 - accuracy: 0.9548 - val_loss: 2.3351 - val_accuracy: 0.6677\n",
      "Epoch 37/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1249 - accuracy: 0.9553 - val_loss: 3.5472 - val_accuracy: 0.5545\n",
      "Epoch 38/50\n",
      "410/410 [==============================] - 13s 33ms/step - loss: 0.1145 - accuracy: 0.9582 - val_loss: 0.9737 - val_accuracy: 0.2970\n",
      "Epoch 39/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1160 - accuracy: 0.9609 - val_loss: 2.5848 - val_accuracy: 0.6506\n",
      "Epoch 40/50\n",
      "410/410 [==============================] - 13s 33ms/step - loss: 0.1325 - accuracy: 0.9536 - val_loss: 7.2770 - val_accuracy: 0.2810\n",
      "Epoch 41/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1165 - accuracy: 0.9597 - val_loss: 1.0502 - val_accuracy: 0.8515\n",
      "Epoch 42/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1129 - accuracy: 0.9658 - val_loss: 1.1862 - val_accuracy: 0.8472\n",
      "Epoch 43/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1160 - accuracy: 0.9580 - val_loss: 1.8562 - val_accuracy: 0.7137\n",
      "Epoch 44/50\n",
      "410/410 [==============================] - 13s 33ms/step - loss: 0.1105 - accuracy: 0.9616 - val_loss: 0.6146 - val_accuracy: 0.9209\n",
      "Epoch 45/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1136 - accuracy: 0.9665 - val_loss: 4.4915 - val_accuracy: 0.0075\n",
      "Epoch 46/50\n",
      "410/410 [==============================] - 13s 32ms/step - loss: 0.1299 - accuracy: 0.9602 - val_loss: 1.7787 - val_accuracy: 0.7436\n",
      "Epoch 47/50\n",
      "410/410 [==============================] - 517s 1s/step - loss: 0.1162 - accuracy: 0.9624 - val_loss: 2.6797 - val_accuracy: 0.6111\n",
      "Epoch 48/50\n",
      "410/410 [==============================] - 17s 42ms/step - loss: 0.1046 - accuracy: 0.9648 - val_loss: 1.8031 - val_accuracy: 0.6859\n",
      "Epoch 49/50\n",
      "410/410 [==============================] - 12s 28ms/step - loss: 0.1131 - accuracy: 0.9638 - val_loss: 2.7762 - val_accuracy: 0.5962\n",
      "Epoch 50/50\n",
      "410/410 [==============================] - 11s 28ms/step - loss: 0.1094 - accuracy: 0.9643 - val_loss: 5.0261 - val_accuracy: 0.4177\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 5.0261 - accuracy: 0.4177\n",
      "Epoch 1/50\n",
      "412/412 [==============================] - 16s 30ms/step - loss: 0.4699 - accuracy: 0.7303 - val_loss: 1.1704 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "412/412 [==============================] - 12s 29ms/step - loss: 0.3881 - accuracy: 0.8025 - val_loss: 0.8241 - val_accuracy: 0.1491\n",
      "Epoch 3/50\n",
      "412/412 [==============================] - 13s 32ms/step - loss: 0.3593 - accuracy: 0.8200 - val_loss: 0.7264 - val_accuracy: 0.4737\n",
      "Epoch 4/50\n",
      "412/412 [==============================] - 13s 30ms/step - loss: 0.3361 - accuracy: 0.8474 - val_loss: 0.2239 - val_accuracy: 0.9759\n",
      "Epoch 5/50\n",
      "412/412 [==============================] - 13s 31ms/step - loss: 0.3206 - accuracy: 0.8605 - val_loss: 0.5185 - val_accuracy: 0.7752\n",
      "Epoch 6/50\n",
      "412/412 [==============================] - 13s 32ms/step - loss: 0.3005 - accuracy: 0.8710 - val_loss: 0.4960 - val_accuracy: 0.7884\n",
      "Epoch 7/50\n",
      "412/412 [==============================] - 13s 32ms/step - loss: 0.3032 - accuracy: 0.8737 - val_loss: 0.6828 - val_accuracy: 0.5680\n",
      "Epoch 8/50\n",
      "412/412 [==============================] - 13s 32ms/step - loss: 0.2906 - accuracy: 0.8841 - val_loss: 0.3779 - val_accuracy: 0.8805\n",
      "Epoch 9/50\n",
      "412/412 [==============================] - 13s 32ms/step - loss: 0.2829 - accuracy: 0.8858 - val_loss: 1.0276 - val_accuracy: 0.2379\n",
      "Epoch 10/50\n",
      "412/412 [==============================] - 13s 32ms/step - loss: 0.2699 - accuracy: 0.8926 - val_loss: 0.6046 - val_accuracy: 0.6480\n",
      "Epoch 11/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2428 - accuracy: 0.9052 - val_loss: 0.6832 - val_accuracy: 0.5559\n",
      "Epoch 12/50\n",
      "412/412 [==============================] - 13s 33ms/step - loss: 0.2443 - accuracy: 0.9113 - val_loss: 0.5661 - val_accuracy: 0.6809\n",
      "Epoch 13/50\n",
      "412/412 [==============================] - 13s 33ms/step - loss: 0.2447 - accuracy: 0.9145 - val_loss: 0.8568 - val_accuracy: 0.3761\n",
      "Epoch 14/50\n",
      "412/412 [==============================] - 13s 32ms/step - loss: 0.2447 - accuracy: 0.9108 - val_loss: 2.5228 - val_accuracy: 0.0219\n",
      "Epoch 15/50\n",
      "412/412 [==============================] - 13s 32ms/step - loss: 0.2356 - accuracy: 0.9152 - val_loss: 1.6731 - val_accuracy: 0.0888\n",
      "Epoch 16/50\n",
      "412/412 [==============================] - 13s 33ms/step - loss: 0.2417 - accuracy: 0.9138 - val_loss: 0.5548 - val_accuracy: 0.6952\n",
      "Epoch 17/50\n",
      "412/412 [==============================] - 13s 33ms/step - loss: 0.2329 - accuracy: 0.9130 - val_loss: 1.9595 - val_accuracy: 0.0548\n",
      "Epoch 18/50\n",
      "412/412 [==============================] - 13s 33ms/step - loss: 0.2347 - accuracy: 0.9159 - val_loss: 2.2663 - val_accuracy: 0.0439\n",
      "Epoch 19/50\n",
      "412/412 [==============================] - 13s 33ms/step - loss: 0.2256 - accuracy: 0.9145 - val_loss: 1.4759 - val_accuracy: 0.1414\n",
      "Epoch 20/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2265 - accuracy: 0.9196 - val_loss: 2.9755 - val_accuracy: 0.0164\n",
      "Epoch 21/50\n",
      "412/412 [==============================] - 13s 32ms/step - loss: 0.2134 - accuracy: 0.9249 - val_loss: 1.8983 - val_accuracy: 0.1031\n",
      "Epoch 22/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2201 - accuracy: 0.9201 - val_loss: 0.9157 - val_accuracy: 0.4550\n",
      "Epoch 23/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2273 - accuracy: 0.9191 - val_loss: 2.3273 - val_accuracy: 0.0362\n",
      "Epoch 24/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2098 - accuracy: 0.9257 - val_loss: 1.9971 - val_accuracy: 0.0746\n",
      "Epoch 25/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2167 - accuracy: 0.9298 - val_loss: 2.6374 - val_accuracy: 0.0252\n",
      "Epoch 26/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2141 - accuracy: 0.9308 - val_loss: 2.2679 - val_accuracy: 0.0406\n",
      "Epoch 27/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2062 - accuracy: 0.9298 - val_loss: 3.0634 - val_accuracy: 0.0175\n",
      "Epoch 28/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2086 - accuracy: 0.9329 - val_loss: 0.8437 - val_accuracy: 0.4781\n",
      "Epoch 29/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2126 - accuracy: 0.9371 - val_loss: 2.9210 - val_accuracy: 0.0175\n",
      "Epoch 30/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1972 - accuracy: 0.9363 - val_loss: 2.0326 - val_accuracy: 0.0746\n",
      "Epoch 31/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2018 - accuracy: 0.9334 - val_loss: 3.4059 - val_accuracy: 0.0164\n",
      "Epoch 32/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1887 - accuracy: 0.9431 - val_loss: 2.1867 - val_accuracy: 0.0461\n",
      "Epoch 33/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2136 - accuracy: 0.9344 - val_loss: 2.5012 - val_accuracy: 0.0285\n",
      "Epoch 34/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.1939 - accuracy: 0.9436 - val_loss: 2.4772 - val_accuracy: 0.0406\n",
      "Epoch 35/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1895 - accuracy: 0.9451 - val_loss: 2.6915 - val_accuracy: 0.0482\n",
      "Epoch 36/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1933 - accuracy: 0.9431 - val_loss: 2.1716 - val_accuracy: 0.0450\n",
      "Epoch 37/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1876 - accuracy: 0.9458 - val_loss: 4.7397 - val_accuracy: 0.0055\n",
      "Epoch 38/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.1809 - accuracy: 0.9463 - val_loss: 2.9889 - val_accuracy: 0.0197\n",
      "Epoch 39/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1890 - accuracy: 0.9463 - val_loss: 1.9024 - val_accuracy: 0.1184\n",
      "Epoch 40/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1769 - accuracy: 0.9470 - val_loss: 2.9099 - val_accuracy: 0.0219\n",
      "Epoch 41/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1869 - accuracy: 0.9473 - val_loss: 3.7648 - val_accuracy: 0.0077\n",
      "Epoch 42/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1794 - accuracy: 0.9485 - val_loss: 3.7932 - val_accuracy: 0.0077\n",
      "Epoch 43/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1669 - accuracy: 0.9534 - val_loss: 4.2242 - val_accuracy: 0.0088\n",
      "Epoch 44/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1615 - accuracy: 0.9631 - val_loss: 6.3421 - val_accuracy: 0.0011\n",
      "Epoch 45/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.1634 - accuracy: 0.9565 - val_loss: 3.8324 - val_accuracy: 0.0121\n",
      "Epoch 46/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1497 - accuracy: 0.9609 - val_loss: 5.1247 - val_accuracy: 0.0022\n",
      "Epoch 47/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1548 - accuracy: 0.9602 - val_loss: 3.7550 - val_accuracy: 0.0121\n",
      "Epoch 48/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.1385 - accuracy: 0.9648 - val_loss: 4.4106 - val_accuracy: 0.0088\n",
      "Epoch 49/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1389 - accuracy: 0.9689 - val_loss: 7.8615 - val_accuracy: 0.0011\n",
      "Epoch 50/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.1260 - accuracy: 0.9674 - val_loss: 3.5311 - val_accuracy: 0.0241\n",
      "29/29 [==============================] - 1s 24ms/step - loss: 3.5311 - accuracy: 0.0241\n",
      "Epoch 1/50\n",
      "412/412 [==============================] - 16s 31ms/step - loss: 0.4286 - accuracy: 0.7724 - val_loss: 0.8616 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "412/412 [==============================] - 14s 35ms/step - loss: 0.3972 - accuracy: 0.7767 - val_loss: 0.7337 - val_accuracy: 0.3311\n",
      "Epoch 3/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.3641 - accuracy: 0.8180 - val_loss: 5.7505 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.3462 - accuracy: 0.8569 - val_loss: 5.4806 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.3365 - accuracy: 0.8605 - val_loss: 5.4585 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.3355 - accuracy: 0.8618 - val_loss: 0.5164 - val_accuracy: 0.8520\n",
      "Epoch 7/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.3326 - accuracy: 0.8642 - val_loss: 2.2047 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.3419 - accuracy: 0.8622 - val_loss: 0.4609 - val_accuracy: 0.8925\n",
      "Epoch 9/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.3240 - accuracy: 0.8766 - val_loss: 0.9546 - val_accuracy: 0.3465\n",
      "Epoch 10/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.3132 - accuracy: 0.8846 - val_loss: 1.2709 - val_accuracy: 0.1425\n",
      "Epoch 11/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.3410 - accuracy: 0.8635 - val_loss: 0.1963 - val_accuracy: 0.9923\n",
      "Epoch 12/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.3139 - accuracy: 0.8875 - val_loss: 0.5215 - val_accuracy: 0.8169\n",
      "Epoch 13/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.3063 - accuracy: 0.8953 - val_loss: 0.5685 - val_accuracy: 0.7336\n",
      "Epoch 14/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.3076 - accuracy: 0.8853 - val_loss: 1.7557 - val_accuracy: 0.0044\n",
      "Epoch 15/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.3125 - accuracy: 0.8870 - val_loss: 0.7030 - val_accuracy: 0.6195\n",
      "Epoch 16/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.3021 - accuracy: 0.8955 - val_loss: 0.6616 - val_accuracy: 0.6535\n",
      "Epoch 17/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.3131 - accuracy: 0.8914 - val_loss: 0.4955 - val_accuracy: 0.8322\n",
      "Epoch 18/50\n",
      "412/412 [==============================] - 14s 33ms/step - loss: 0.2976 - accuracy: 0.8997 - val_loss: 0.7654 - val_accuracy: 0.5515\n",
      "Epoch 19/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2979 - accuracy: 0.8972 - val_loss: 0.5223 - val_accuracy: 0.7785\n",
      "Epoch 20/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2947 - accuracy: 0.8948 - val_loss: 0.6403 - val_accuracy: 0.7039\n",
      "Epoch 21/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2974 - accuracy: 0.9001 - val_loss: 0.2380 - val_accuracy: 0.9627\n",
      "Epoch 22/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2873 - accuracy: 0.9031 - val_loss: 0.3722 - val_accuracy: 0.9090\n",
      "Epoch 23/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2905 - accuracy: 0.8984 - val_loss: 0.1678 - val_accuracy: 0.9836\n",
      "Epoch 24/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2971 - accuracy: 0.8938 - val_loss: 0.9067 - val_accuracy: 0.4123\n",
      "Epoch 25/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2783 - accuracy: 0.9055 - val_loss: 1.3270 - val_accuracy: 0.1129\n",
      "Epoch 26/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2892 - accuracy: 0.9006 - val_loss: 0.8167 - val_accuracy: 0.4836\n",
      "Epoch 27/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2966 - accuracy: 0.8970 - val_loss: 0.1829 - val_accuracy: 0.9846\n",
      "Epoch 28/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2878 - accuracy: 0.8977 - val_loss: 0.2190 - val_accuracy: 0.9660\n",
      "Epoch 29/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2799 - accuracy: 0.9018 - val_loss: 0.0625 - val_accuracy: 0.9978\n",
      "Epoch 30/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2769 - accuracy: 0.9101 - val_loss: 0.0880 - val_accuracy: 0.9978\n",
      "Epoch 31/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2652 - accuracy: 0.9074 - val_loss: 0.3165 - val_accuracy: 0.9232\n",
      "Epoch 32/50\n",
      "412/412 [==============================] - 14s 35ms/step - loss: 0.2751 - accuracy: 0.9040 - val_loss: 0.4869 - val_accuracy: 0.8158\n",
      "Epoch 33/50\n",
      "412/412 [==============================] - 14s 35ms/step - loss: 0.2872 - accuracy: 0.8946 - val_loss: 1.2419 - val_accuracy: 0.1283\n",
      "Epoch 34/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2713 - accuracy: 0.9089 - val_loss: 0.3017 - val_accuracy: 0.9441\n",
      "Epoch 35/50\n",
      "412/412 [==============================] - 14s 35ms/step - loss: 0.2642 - accuracy: 0.9130 - val_loss: 0.0306 - val_accuracy: 0.9989\n",
      "Epoch 36/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2646 - accuracy: 0.9140 - val_loss: 0.7641 - val_accuracy: 0.5307\n",
      "Epoch 37/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2779 - accuracy: 0.9123 - val_loss: 0.0308 - val_accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2601 - accuracy: 0.9140 - val_loss: 0.3927 - val_accuracy: 0.8860\n",
      "Epoch 39/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2603 - accuracy: 0.9111 - val_loss: 0.0803 - val_accuracy: 0.9967\n",
      "Epoch 40/50\n",
      "412/412 [==============================] - 14s 35ms/step - loss: 0.2747 - accuracy: 0.9023 - val_loss: 1.3079 - val_accuracy: 0.1513\n",
      "Epoch 41/50\n",
      "412/412 [==============================] - 14s 35ms/step - loss: 0.2560 - accuracy: 0.9155 - val_loss: 0.7026 - val_accuracy: 0.6096\n",
      "Epoch 42/50\n",
      "412/412 [==============================] - 14s 35ms/step - loss: 0.2521 - accuracy: 0.9123 - val_loss: 0.4522 - val_accuracy: 0.8498\n",
      "Epoch 43/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2675 - accuracy: 0.9077 - val_loss: 0.3728 - val_accuracy: 0.8991\n",
      "Epoch 44/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2613 - accuracy: 0.9048 - val_loss: 0.3621 - val_accuracy: 0.8958\n",
      "Epoch 45/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2529 - accuracy: 0.9150 - val_loss: 0.4079 - val_accuracy: 0.8805\n",
      "Epoch 46/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2579 - accuracy: 0.9086 - val_loss: 0.7465 - val_accuracy: 0.5658\n",
      "Epoch 47/50\n",
      "412/412 [==============================] - 14s 34ms/step - loss: 0.2677 - accuracy: 0.9031 - val_loss: 0.2713 - val_accuracy: 0.9386\n",
      "Epoch 48/50\n",
      "412/412 [==============================] - 14s 35ms/step - loss: 0.2557 - accuracy: 0.9125 - val_loss: 0.0701 - val_accuracy: 0.9989\n",
      "Epoch 49/50\n",
      "412/412 [==============================] - 14s 35ms/step - loss: 0.2631 - accuracy: 0.9006 - val_loss: 0.1244 - val_accuracy: 0.9923\n",
      "Epoch 50/50\n",
      "412/412 [==============================] - 15s 37ms/step - loss: 0.2508 - accuracy: 0.9067 - val_loss: 0.4560 - val_accuracy: 0.8443\n",
      "29/29 [==============================] - 1s 27ms/step - loss: 0.4560 - accuracy: 0.8443\n",
      "Epoch 1/50\n",
      "418/418 [==============================] - 17s 33ms/step - loss: 0.5953 - accuracy: 0.6422 - val_loss: 0.0144 - val_accuracy: 0.9918\n",
      "Epoch 2/50\n",
      "418/418 [==============================] - 14s 35ms/step - loss: 0.4947 - accuracy: 0.7716 - val_loss: 0.0406 - val_accuracy: 0.9918\n",
      "Epoch 3/50\n",
      "418/418 [==============================] - 16s 37ms/step - loss: 0.4635 - accuracy: 0.8123 - val_loss: 0.0575 - val_accuracy: 0.9918\n",
      "Epoch 4/50\n",
      "418/418 [==============================] - 14s 33ms/step - loss: 0.4487 - accuracy: 0.8204 - val_loss: 0.0675 - val_accuracy: 0.9906\n",
      "Epoch 5/50\n",
      "418/418 [==============================] - 14s 34ms/step - loss: 0.4428 - accuracy: 0.8410 - val_loss: 0.0777 - val_accuracy: 0.9906\n",
      "Epoch 6/50\n",
      "418/418 [==============================] - 14s 34ms/step - loss: 0.4287 - accuracy: 0.8307 - val_loss: 0.0893 - val_accuracy: 0.9906\n",
      "Epoch 7/50\n",
      "418/418 [==============================] - 14s 34ms/step - loss: 0.4203 - accuracy: 0.8441 - val_loss: 0.1040 - val_accuracy: 0.9883\n",
      "Epoch 8/50\n",
      "418/418 [==============================] - 14s 34ms/step - loss: 0.4346 - accuracy: 0.8391 - val_loss: 0.1090 - val_accuracy: 0.9883\n",
      "Epoch 9/50\n",
      "418/418 [==============================] - 14s 34ms/step - loss: 0.4161 - accuracy: 0.8417 - val_loss: 0.1229 - val_accuracy: 0.9883\n",
      "Epoch 10/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.4142 - accuracy: 0.8448 - val_loss: 0.1350 - val_accuracy: 0.9883\n",
      "Epoch 11/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.4172 - accuracy: 0.8432 - val_loss: 0.1385 - val_accuracy: 0.9883\n",
      "Epoch 12/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.4039 - accuracy: 0.8491 - val_loss: 0.1535 - val_accuracy: 0.9883\n",
      "Epoch 13/50\n",
      "418/418 [==============================] - 14s 35ms/step - loss: 0.4019 - accuracy: 0.8503 - val_loss: 0.1678 - val_accuracy: 0.9883\n",
      "Epoch 14/50\n",
      "418/418 [==============================] - 14s 35ms/step - loss: 0.4030 - accuracy: 0.8491 - val_loss: 0.1677 - val_accuracy: 0.9883\n",
      "Epoch 15/50\n",
      "418/418 [==============================] - 15s 36ms/step - loss: 0.3862 - accuracy: 0.8578 - val_loss: 0.1815 - val_accuracy: 0.9883\n",
      "Epoch 16/50\n",
      "418/418 [==============================] - 15s 36ms/step - loss: 0.3799 - accuracy: 0.8537 - val_loss: 0.1977 - val_accuracy: 0.9883\n",
      "Epoch 17/50\n",
      "418/418 [==============================] - 14s 35ms/step - loss: 0.3751 - accuracy: 0.8621 - val_loss: 0.2069 - val_accuracy: 0.9883\n",
      "Epoch 18/50\n",
      "418/418 [==============================] - 14s 34ms/step - loss: 0.3668 - accuracy: 0.8649 - val_loss: 0.2246 - val_accuracy: 0.9883\n",
      "Epoch 19/50\n",
      "418/418 [==============================] - 14s 35ms/step - loss: 0.3856 - accuracy: 0.8635 - val_loss: 0.2165 - val_accuracy: 0.9883\n",
      "Epoch 20/50\n",
      "418/418 [==============================] - 14s 35ms/step - loss: 0.3855 - accuracy: 0.8599 - val_loss: 0.2099 - val_accuracy: 0.9883\n",
      "Epoch 21/50\n",
      "418/418 [==============================] - 14s 34ms/step - loss: 0.3741 - accuracy: 0.8661 - val_loss: 0.2116 - val_accuracy: 0.9883\n",
      "Epoch 22/50\n",
      "418/418 [==============================] - 14s 34ms/step - loss: 0.3591 - accuracy: 0.8748 - val_loss: 0.2292 - val_accuracy: 0.9871\n",
      "Epoch 23/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3608 - accuracy: 0.8752 - val_loss: 0.2307 - val_accuracy: 0.9883\n",
      "Epoch 24/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3599 - accuracy: 0.8772 - val_loss: 0.2281 - val_accuracy: 0.9883\n",
      "Epoch 25/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3559 - accuracy: 0.8810 - val_loss: 0.2308 - val_accuracy: 0.9883\n",
      "Epoch 26/50\n",
      "418/418 [==============================] - 14s 34ms/step - loss: 0.3567 - accuracy: 0.8793 - val_loss: 0.2300 - val_accuracy: 0.9883\n",
      "Epoch 27/50\n",
      "418/418 [==============================] - 14s 35ms/step - loss: 0.3616 - accuracy: 0.8822 - val_loss: 0.2180 - val_accuracy: 0.9883\n",
      "Epoch 28/50\n",
      "418/418 [==============================] - 15s 36ms/step - loss: 0.3443 - accuracy: 0.8774 - val_loss: 0.2373 - val_accuracy: 0.9883\n",
      "Epoch 29/50\n",
      "418/418 [==============================] - 14s 35ms/step - loss: 0.3424 - accuracy: 0.8824 - val_loss: 0.2341 - val_accuracy: 0.9883\n",
      "Epoch 30/50\n",
      "418/418 [==============================] - 14s 34ms/step - loss: 0.3346 - accuracy: 0.8831 - val_loss: 0.2418 - val_accuracy: 0.9883\n",
      "Epoch 31/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3341 - accuracy: 0.8831 - val_loss: 0.2478 - val_accuracy: 0.9883\n",
      "Epoch 32/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3229 - accuracy: 0.8877 - val_loss: 0.2598 - val_accuracy: 0.9871\n",
      "Epoch 33/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3251 - accuracy: 0.8913 - val_loss: 0.2633 - val_accuracy: 0.9883\n",
      "Epoch 34/50\n",
      "418/418 [==============================] - 14s 35ms/step - loss: 0.3192 - accuracy: 0.8918 - val_loss: 0.2530 - val_accuracy: 0.9871\n",
      "Epoch 35/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3259 - accuracy: 0.8932 - val_loss: 0.2706 - val_accuracy: 0.9871\n",
      "Epoch 36/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3133 - accuracy: 0.8966 - val_loss: 0.2585 - val_accuracy: 0.9871\n",
      "Epoch 37/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3162 - accuracy: 0.8958 - val_loss: 0.2910 - val_accuracy: 0.9871\n",
      "Epoch 38/50\n",
      "418/418 [==============================] - 14s 35ms/step - loss: 0.3111 - accuracy: 0.8963 - val_loss: 0.3064 - val_accuracy: 0.9871\n",
      "Epoch 39/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3125 - accuracy: 0.8980 - val_loss: 0.3056 - val_accuracy: 0.9871\n",
      "Epoch 40/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.3053 - accuracy: 0.8944 - val_loss: 0.3044 - val_accuracy: 0.9871\n",
      "Epoch 41/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.2909 - accuracy: 0.9092 - val_loss: 0.3437 - val_accuracy: 0.9871\n",
      "Epoch 42/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.2955 - accuracy: 0.9021 - val_loss: 0.3392 - val_accuracy: 0.9871\n",
      "Epoch 43/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.2944 - accuracy: 0.9037 - val_loss: 0.3222 - val_accuracy: 0.9871\n",
      "Epoch 44/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.2688 - accuracy: 0.9162 - val_loss: 0.3545 - val_accuracy: 0.9871\n",
      "Epoch 45/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.2789 - accuracy: 0.9164 - val_loss: 0.2989 - val_accuracy: 0.9871\n",
      "Epoch 46/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.2619 - accuracy: 0.9176 - val_loss: 0.3492 - val_accuracy: 0.9859\n",
      "Epoch 47/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.2674 - accuracy: 0.9181 - val_loss: 0.4018 - val_accuracy: 0.9871\n",
      "Epoch 48/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.2547 - accuracy: 0.9243 - val_loss: 0.3833 - val_accuracy: 0.9859\n",
      "Epoch 49/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.2730 - accuracy: 0.9174 - val_loss: 0.3489 - val_accuracy: 0.9859\n",
      "Epoch 50/50\n",
      "418/418 [==============================] - 15s 35ms/step - loss: 0.2446 - accuracy: 0.9227 - val_loss: 0.4036 - val_accuracy: 0.9859\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 0.4036 - accuracy: 0.9859\n",
      "Epoch 1/50\n",
      "362/362 [==============================] - 16s 35ms/step - loss: 0.5294 - accuracy: 0.7364 - val_loss: 0.8639 - val_accuracy: 0.4068\n",
      "Epoch 2/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.4283 - accuracy: 0.7901 - val_loss: 0.6443 - val_accuracy: 0.4816\n",
      "Epoch 3/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3784 - accuracy: 0.8400 - val_loss: 0.7011 - val_accuracy: 0.5268\n",
      "Epoch 4/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3408 - accuracy: 0.8558 - val_loss: 0.3094 - val_accuracy: 0.8510\n",
      "Epoch 5/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3416 - accuracy: 0.8660 - val_loss: 0.9049 - val_accuracy: 0.4823\n",
      "Epoch 6/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3276 - accuracy: 0.8707 - val_loss: 2.0031 - val_accuracy: 0.4040\n",
      "Epoch 7/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3293 - accuracy: 0.8715 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 8/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3353 - accuracy: 0.8649 - val_loss: 1.0352 - val_accuracy: 0.4527\n",
      "Epoch 9/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.3183 - accuracy: 0.8696 - val_loss: 0.9208 - val_accuracy: 0.4908\n",
      "Epoch 10/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3291 - accuracy: 0.8660 - val_loss: 3.6016 - val_accuracy: 0.4032\n",
      "Epoch 11/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3257 - accuracy: 0.8682 - val_loss: 1.6312 - val_accuracy: 0.4068\n",
      "Epoch 12/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.3222 - accuracy: 0.8710 - val_loss: 0.8348 - val_accuracy: 0.5417\n",
      "Epoch 13/50\n",
      "362/362 [==============================] - 14s 37ms/step - loss: 0.3131 - accuracy: 0.8765 - val_loss: 2.2716 - val_accuracy: 0.4061\n",
      "Epoch 14/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.2873 - accuracy: 0.8851 - val_loss: 3.8690e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3083 - accuracy: 0.8760 - val_loss: 1.2171 - val_accuracy: 0.4456\n",
      "Epoch 16/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3119 - accuracy: 0.8738 - val_loss: 1.7998 - val_accuracy: 0.4089\n",
      "Epoch 17/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.3013 - accuracy: 0.8776 - val_loss: 3.3256 - val_accuracy: 0.4061\n",
      "Epoch 18/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.2721 - accuracy: 0.8906 - val_loss: 2.5613 - val_accuracy: 0.4075\n",
      "Epoch 19/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.2773 - accuracy: 0.8931 - val_loss: 2.5240 - val_accuracy: 0.4068\n",
      "Epoch 20/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.2663 - accuracy: 0.8984 - val_loss: 3.5651 - val_accuracy: 0.4047\n",
      "Epoch 21/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2547 - accuracy: 0.9017 - val_loss: 1.8671 - val_accuracy: 0.4103\n",
      "Epoch 22/50\n",
      "362/362 [==============================] - 15s 41ms/step - loss: 0.2580 - accuracy: 0.9014 - val_loss: 3.2196 - val_accuracy: 0.4061\n",
      "Epoch 23/50\n",
      "362/362 [==============================] - 14s 37ms/step - loss: 0.2338 - accuracy: 0.9114 - val_loss: 0.3504 - val_accuracy: 0.8001\n",
      "Epoch 24/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2363 - accuracy: 0.9061 - val_loss: 3.1649 - val_accuracy: 0.4061\n",
      "Epoch 25/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2407 - accuracy: 0.9086 - val_loss: 1.8964 - val_accuracy: 0.4096\n",
      "Epoch 26/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.2362 - accuracy: 0.9048 - val_loss: 2.1036 - val_accuracy: 0.4096\n",
      "Epoch 27/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2325 - accuracy: 0.9092 - val_loss: 1.0076 - val_accuracy: 0.5374\n",
      "Epoch 28/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2273 - accuracy: 0.9109 - val_loss: 2.0249 - val_accuracy: 0.4103\n",
      "Epoch 29/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2343 - accuracy: 0.9056 - val_loss: 2.5026 - val_accuracy: 0.4082\n",
      "Epoch 30/50\n",
      "362/362 [==============================] - 15s 42ms/step - loss: 0.2329 - accuracy: 0.9103 - val_loss: 2.2456 - val_accuracy: 0.4096\n",
      "Epoch 31/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2509 - accuracy: 0.9073 - val_loss: 1.7986 - val_accuracy: 0.4153\n",
      "Epoch 32/50\n",
      "362/362 [==============================] - 14s 37ms/step - loss: 0.2249 - accuracy: 0.9067 - val_loss: 3.9485 - val_accuracy: 0.4061\n",
      "Epoch 33/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.2286 - accuracy: 0.9111 - val_loss: 1.8979 - val_accuracy: 0.4237\n",
      "Epoch 34/50\n",
      "362/362 [==============================] - 14s 37ms/step - loss: 0.2213 - accuracy: 0.9133 - val_loss: 4.8228 - val_accuracy: 0.4047\n",
      "Epoch 35/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2362 - accuracy: 0.9064 - val_loss: 1.3977 - val_accuracy: 0.4689\n",
      "Epoch 36/50\n",
      "362/362 [==============================] - 14s 37ms/step - loss: 0.2461 - accuracy: 0.9001 - val_loss: 2.1751 - val_accuracy: 0.4089\n",
      "Epoch 37/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2224 - accuracy: 0.9064 - val_loss: 0.2180 - val_accuracy: 0.9061\n",
      "Epoch 38/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.2198 - accuracy: 0.9156 - val_loss: 4.7627 - val_accuracy: 0.4061\n",
      "Epoch 39/50\n",
      "362/362 [==============================] - 14s 37ms/step - loss: 0.2297 - accuracy: 0.9089 - val_loss: 3.0013 - val_accuracy: 0.4068\n",
      "Epoch 40/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.2314 - accuracy: 0.9073 - val_loss: 4.1904 - val_accuracy: 0.4068\n",
      "Epoch 41/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.2480 - accuracy: 0.8976 - val_loss: 3.4046 - val_accuracy: 0.4061\n",
      "Epoch 42/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2268 - accuracy: 0.9067 - val_loss: 4.4707 - val_accuracy: 0.4061\n",
      "Epoch 43/50\n",
      "362/362 [==============================] - 13s 37ms/step - loss: 0.2153 - accuracy: 0.9169 - val_loss: 1.2042 - val_accuracy: 0.5184\n",
      "Epoch 44/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2115 - accuracy: 0.9145 - val_loss: 3.7951 - val_accuracy: 0.3997\n",
      "Epoch 45/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2173 - accuracy: 0.9117 - val_loss: 4.7449 - val_accuracy: 0.4061\n",
      "Epoch 46/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2282 - accuracy: 0.9084 - val_loss: 3.4464 - val_accuracy: 0.4061\n",
      "Epoch 47/50\n",
      "362/362 [==============================] - 14s 37ms/step - loss: 0.2311 - accuracy: 0.9050 - val_loss: 3.8841 - val_accuracy: 0.4061\n",
      "Epoch 48/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2218 - accuracy: 0.9084 - val_loss: 1.9072 - val_accuracy: 0.4145\n",
      "Epoch 49/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2191 - accuracy: 0.9067 - val_loss: 1.2174 - val_accuracy: 0.4936\n",
      "Epoch 50/50\n",
      "362/362 [==============================] - 14s 38ms/step - loss: 0.2166 - accuracy: 0.9136 - val_loss: 4.1652 - val_accuracy: 0.4061\n",
      "45/45 [==============================] - 1s 27ms/step - loss: 4.1652 - accuracy: 0.4061\n"
     ]
    }
   ],
   "source": [
    "accuracy=[]\n",
    "for train_index, val_index in gkf.split(data_array, label_array, groups=group_array):\n",
    "    train_features,train_labels=data_array[train_index],label_array[train_index]\n",
    "    val_features,val_labels=data_array[val_index],label_array[val_index]\n",
    "    scaler=StandardScaler()\n",
    "    train_features = scaler.fit_transform(train_features.reshape(-1, train_features.shape[-1])).reshape(train_features.shape)\n",
    "    val_features = scaler.transform(val_features.reshape(-1, val_features.shape[-1])).reshape(val_features.shape)\n",
    "    model=cnnmodel()\n",
    "    model.fit(train_features,train_labels,epochs=50,batch_size=10,validation_data=(val_features,val_labels))\n",
    "    accuracy.append(model.evaluate(val_features,val_labels)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.535629004612565"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../models/cnnmodel.pickle' , 'wb')as file:\n",
    "     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
